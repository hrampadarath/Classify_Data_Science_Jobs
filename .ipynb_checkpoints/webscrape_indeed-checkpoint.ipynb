{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Indeed and classifying Data Science Jobs\n",
    "\n",
    "\n",
    "In this project, I will be looking into building a job classifier. This project has 4 main parts:\n",
    "\n",
    "1. web scraping the Indded website for data science job postings\n",
    "2. bulid a classifier to classify the differnt data science types/levels\n",
    "3. classify a real data scientist based upon skills, experience etc\n",
    "4. provide a list of skills required for a data scientist to move one level up\n",
    "\n",
    "\n",
    "The first part (web scraping) is based on the tutroail at https://github.com/aakashtandel/Web-Scraping-Indeed/blob/master/Code/Project%203%20-%20Web%20Scraping%20Indeed%20Job%20Listings%20Jupyter%20Notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scraping job listings from https://www.indeed.co.uk/\n",
    "\n",
    "We will be scraping listings from indeed.co.uk using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.indeed.co.uk/jobs?q=data%20scientist&l=Bristol&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ = soup.find_all(class_= \"result\")\n",
    "len(results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a single result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"jobsearch-SerpJobCard unifiedRow row result\" data-jk=\"fbffdf3b8f6b438c\" data-tn-component=\"organicJob\" id=\"p_fbffdf3b8f6b438c\">\n",
       "<h2 class=\"title\">\n",
       "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=fbffdf3b8f6b438c&amp;fccid=b6893c92ad39abbc&amp;vjs=3\" id=\"jl_fbffdf3b8f6b438c\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[4],true,0);\" onmousedown=\"return rclk(this,jobmap[4],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Machine Learning Engineer\">\n",
       "Machine Learning Engineer</a>\n",
       "</h2>\n",
       "<div class=\"sjcl\">\n",
       "<div>\n",
       "<span class=\"company\">\n",
       "Ultraleap Ltd.</span>\n",
       "</div>\n",
       "<div class=\"recJobLoc\" data-rc-loc=\"Bristol\" id=\"recJobLoc_fbffdf3b8f6b438c\" style=\"display: none\"></div>\n",
       "<span class=\"location accessible-contrast-color-location\">Bristol</span>\n",
       "</div>\n",
       "<table class=\"jobCardShelfContainer\"><tr class=\"jobCardShelf\"><td class=\"jobCardShelfItem indeedApply\"><span class=\"jobCardShelfIcon\"><svg fill=\"none\" height=\"16\" viewbox=\"0 0 20 20\" width=\"16\"><rect fill=\"#FF5A1F\" height=\"20\" rx=\"10\" width=\"20\"></rect><path clip-rule=\"evenodd\" d=\"M15.3125 4.0625L10.8125 15.3125L7.99999 11.375L15.3125 4.0625ZM7.604 12.7576L6.875 15.3125L8.567 14.1054L7.604 12.7576ZM7.20463 10.5796L12.419 5.36525L4.0625 9.125L6.9875 10.7968L7.20463 10.5796Z\" fill=\"white\" fill-rule=\"evenodd\"></path></svg></span><span class=\"iaLabel iaIconActive\">Easily apply to this job</span></td></tr></table><div class=\"summary\">\n",
       "<ul style=\"list-style-type:circle;margin-top: 0px;margin-bottom: 0px;padding-left:20px;\">\n",
       "<li>Research, code and deliver alongside our product and engineering team to test and release new hand-tracking features to our users worldwide;</li>\n",
       "</ul></div>\n",
       "<div class=\"jobsearch-SerpJobCard-footer\">\n",
       "<div class=\"jobsearch-SerpJobCard-footerActions\">\n",
       "<div class=\"result-link-bar-container\">\n",
       "<div class=\"result-link-bar\"><span class=\"date\">30+ days ago</span><span class=\"tt_set\" id=\"tt_set_4\"><div class=\"job-reaction\"><span aria-expanded=\"false\" aria-haspopup=\"true\" aria-label=\"save or dislike\" class=\"job-reaction-kebab\" data-ol-has-click-handler=\"\" onclick=\"toggleKebabMenu('fbffdf3b8f6b438c', false, event); return false;\" role=\"button\" tabindex=\"0\"></span><span class=\"job-reaction-kebab-menu\"><a class=\"job-reaction-kebab-item\" data-ol-has-click-handler=\"\" href=\"#\" onclick=\"changeJobState('fbffdf3b8f6b438c', 'save', 'linkbar', false, '');return false;\"><svg focusable=\"false\" height=\"16\" viewbox=\"0 0 24 24\" width=\"16\"><g><path d=\"M16.5,3A6,6,0,0,0,12,5.09,6,6,0,0,0,7.5,3,5.45,5.45,0,0,0,2,8.5C2,12.28,5.4,15.36,10.55,20L12,21.35,13.45,20C18.6,15.36,22,12.28,22,8.5A5.45,5.45,0,0,0,16.5,3ZM12.1,18.55l-0.1.1-0.1-.1C7.14,14.24,4,11.39,4,8.5A3.42,3.42,0,0,1,7.5,5a3.91,3.91,0,0,1,3.57,2.36h1.87A3.88,3.88,0,0,1,16.5,5,3.42,3.42,0,0,1,20,8.5C20,11.39,16.86,14.24,12.1,18.55Z\" fill=\"#2d2d2d\"></path></g></svg><span class=\"job-reaction-kebab-item-text\">Save job</span></a><a class=\"job-reaction-kebab-item\" data-ol-has-click-handler=\"\" href=\"#\" onclick=\"dislikeJob(false, false, 'fbffdf3b8f6b438c', 'unsave', 'linkbar', false, ''); return false;\"><span class=\"job-reaction-dislike-icon\"></span><span class=\"job-reaction-kebab-item-text\">Not interested</span></a></span></div><span class=\"result-link-bar-separator\">·</span><a class=\"sl resultLink save-job-link\" href=\"#\" id=\"sj_fbffdf3b8f6b438c\" onclick=\"changeJobState('fbffdf3b8f6b438c', 'save', 'linkbar', false, ''); return false;\" title=\"Save this job to my.indeed\">Save job</a><span class=\"result-link-bar-separator\">·</span><a class=\"sl resultLink more-link\" href=\"#\" id=\"tog_4\" onclick=\"toggleMoreLinks('fbffdf3b8f6b438c'); return false;\">More...</a></span><div class=\"edit_note_content\" id=\"editsaved2_fbffdf3b8f6b438c\" style=\"display:none;\"></div><script>if (!window['result_fbffdf3b8f6b438c']) {window['result_fbffdf3b8f6b438c'] = {};}window['result_fbffdf3b8f6b438c']['showSource'] = false; window['result_fbffdf3b8f6b438c']['source'] = \"Ultraleap Ltd.\"; window['result_fbffdf3b8f6b438c']['loggedIn'] = false; window['result_fbffdf3b8f6b438c']['showMyJobsLinks'] = false;window['result_fbffdf3b8f6b438c']['undoAction'] = \"unsave\";window['result_fbffdf3b8f6b438c']['relativeJobAge'] = \"30+ days ago\";window['result_fbffdf3b8f6b438c']['jobKey'] = \"fbffdf3b8f6b438c\"; window['result_fbffdf3b8f6b438c']['myIndeedAvailable'] = true; window['result_fbffdf3b8f6b438c']['showMoreActionsLink'] = window['result_fbffdf3b8f6b438c']['showMoreActionsLink'] || true; window['result_fbffdf3b8f6b438c']['resultNumber'] = 4; window['result_fbffdf3b8f6b438c']['jobStateChangedToSaved'] = false; window['result_fbffdf3b8f6b438c']['searchState'] = \"q=data scientist&amp;l=Bristol&amp;start=10\"; window['result_fbffdf3b8f6b438c']['basicPermaLink'] = \"https://www.indeed.co.uk\"; window['result_fbffdf3b8f6b438c']['saveJobFailed'] = false; window['result_fbffdf3b8f6b438c']['removeJobFailed'] = false; window['result_fbffdf3b8f6b438c']['requestPending'] = false; window['result_fbffdf3b8f6b438c']['notesEnabled'] = true; window['result_fbffdf3b8f6b438c']['currentPage'] = \"serp\"; window['result_fbffdf3b8f6b438c']['sponsored'] = false;window['result_fbffdf3b8f6b438c']['reportJobButtonEnabled'] = false; window['result_fbffdf3b8f6b438c']['showMyJobsHired'] = false; window['result_fbffdf3b8f6b438c']['showSaveForSponsored'] = false; window['result_fbffdf3b8f6b438c']['showJobAge'] = true; window['result_fbffdf3b8f6b438c']['showHolisticCard'] = true; window['result_fbffdf3b8f6b438c']['showDislike'] = true; window['result_fbffdf3b8f6b438c']['showKebab'] = true;</script></div></div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"tab-container\">\n",
       "<div class=\"more-links-container result-tab\" id=\"tt_display_4\" style=\"display:none;\"><a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('fbffdf3b8f6b438c'); return false;\" title=\"Close\"></a><div class=\"more_actions\" id=\"more_4\"><ul><li><span class=\"mat\">View all <a href=\"/Ultraleap-Ltd.-jobs\">Ultraleap Ltd. jobs</a> - <a href=\"/jobs-in-Bristol\">Bristol jobs</a></span></li><li><span class=\"mat\">Salary Search: <a href=\"/salaries/machine-learning-engineer-Salaries,-Bristol-ENG\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=fbffdf3b8f6b438c&amp;from=serp-more');\">Machine Learning Engineer salaries in Bristol</a></span></li></ul></div></div><div class=\"dya-container result-tab\"></div>\n",
       "<div class=\"tellafriend-container result-tab email_job_content\"></div>\n",
       "<div class=\"sign-in-container result-tab\"></div>\n",
       "<div class=\"notes-container result-tab\"></div>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our classifier we need: \n",
    "1. the job title: which is an attribute in the jobtitle class\n",
    "2. the description: which can be accessed through the href link in the jobtitle class\n",
    "\n",
    "Other information that may be important, but not necessarily are;\n",
    "1. the location\n",
    "2. company name\n",
    "3. salary\n",
    "\n",
    "let's find all 5 in our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=fbffdf3b8f6b438c&amp;fccid=b6893c92ad39abbc&amp;vjs=3\" id=\"jl_fbffdf3b8f6b438c\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[4],true,0);\" onmousedown=\"return rclk(this,jobmap[4],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Machine Learning Engineer\">\n",
       "Machine Learning Engineer</a>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti_ = results_[4].find(class_='jobtitle')\n",
    "ti_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': '_blank',\n",
       " 'id': 'jl_fbffdf3b8f6b438c',\n",
       " 'href': '/rc/clk?jk=fbffdf3b8f6b438c&fccid=b6893c92ad39abbc&vjs=3',\n",
       " 'onmousedown': 'return rclk(this,jobmap[4],0);',\n",
       " 'onclick': 'setRefineByCookie([]); return rclk(this,jobmap[4],true,0);',\n",
       " 'rel': ['noopener', 'nofollow'],\n",
       " 'title': 'Machine Learning Engineer',\n",
       " 'class': ['jobtitle', 'turnstileLink'],\n",
       " 'data-tn-element': 'jobTitle'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti_.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Engineer'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the title\n",
    "ti_.attrs[\"title\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are looking for an experienced and motivated top-level Machine Learning Engineer for our spatial tracking team in the UK which is focused on developing new ways for humans and machines to interact.\\n\\nResponsibilities\\n\\nResearch, code and deliver alongside our product and engineering team to test and release new hand-tracking features to our users worldwide;\\nApply mathematical techniques (geometry, linear algebra, numerical methods), machine learning and artificial intelligence techniques to improve spatial tracking;\\nOptimise models to satisfy performance criteria, including mapping to software on various platforms;\\nParticipate in high quality processes including reviews, test, verification, and process improvement.\\n\\nExperience and Skill-Set\\n\\nAn MSc or PhD in a quantitative field of STEM, Computer Science or Engineering with a focus on Machine Learning or industry experience in Machine Learning related work;\\nStrong experience in applied mathematics, algorithm design and performance optimisation;\\nExcellent coding and software development skills including Python and Tensorflow /Keras;\\nExperience with any physics simulator, video game physics or computer graphics is a plus;\\nMotivated, energetic and ready to own challenges.\\n\\nGeneral Information\\n\\nYou must be authorised to work in the UK\\nThis position reports into the Tracking Team Lead;\\nThis position is based in Bristol, UK;\\nOccasional international travel may be required;'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the description\n",
    "#to get teh descrition we will need to extract the data from the url\n",
    "# it exists in class=\"jobsearch-jobDescriptionText\"\n",
    "\n",
    "URL_ = \"https://www.indeed.co.uk\"+ti_.attrs[\"href\"]\n",
    "html_ = requests.get(URL_)\n",
    "soup_ = BeautifulSoup(html_.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "soup_.find(class_= \"jobsearch-jobDescriptionText\").text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge with the parse function from https://github.com/aakashtandel/Web-Scraping-Indeed/blob/master/Code/Project%203%20-%20Web%20Scraping%20Indeed%20Job%20Listings%20Jupyter%20Notebook.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Description\"])\n",
    "    for each in soup.find_all(class_= \"result\" ):\n",
    "        try: \n",
    "            title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "        try:\n",
    "            location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "        except:\n",
    "            location = 'None'\n",
    "        try: \n",
    "            company = each.find(class_='company').text.replace('\\n', '')\n",
    "        except:\n",
    "            company = 'None'\n",
    "        try:\n",
    "            salary = each.find('span', {'class':'no-wrap'}).text\n",
    "        except:\n",
    "            salary = 'None'\n",
    "        \n",
    "        url_ = \"https://www.indeed.co.uk\" + each.find(class_='jobtitle').attrs[\"href\"]\n",
    "        html_ = requests.get(url_)\n",
    "        soup_ = BeautifulSoup(html_.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        description = soup_.find(class_= \"jobsearch-jobDescriptionText\").text.strip()\n",
    "        \n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Description':description}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior/Mid-Level Data Analyst or Scientist</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Heat Recruitment</td>\n",
       "      <td>\\n\\n£25,000 - £40,000 a year\\n</td>\n",
       "      <td>I’m very pleased to be working with a superb B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Prolancer</td>\n",
       "      <td>\\n\\n£50,000 - £65,000 a year\\n</td>\n",
       "      <td>One of the world’s leading financial consultat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist - Electrical Power Systems</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Toumetis</td>\n",
       "      <td>None</td>\n",
       "      <td>TouMetis Job Description\\n\\nSenior Data Scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research Associate or Senior Research Associat...</td>\n",
       "      <td>Bristol BS8</td>\n",
       "      <td>University of Bristol</td>\n",
       "      <td>\\n\\n£33,797 - £38,017 a year\\n</td>\n",
       "      <td>We have an exciting opportunity for a talented...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Ultraleap Ltd.</td>\n",
       "      <td>None</td>\n",
       "      <td>We are looking for an experienced and motivate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist - Bristol University Team</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>LV=Careers</td>\n",
       "      <td>None</td>\n",
       "      <td>Location\\nBristol\\nRef\\nGI007058\\nClosing date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Engineer (C++/Python), AI/Machine Lea...</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Linux Recruit</td>\n",
       "      <td>\\n\\n£45,000 - £70,000 a year\\n</td>\n",
       "      <td>Artificial Intelligence, or simply 'AI', is on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Graduate Data Scientist</td>\n",
       "      <td>Newport</td>\n",
       "      <td>Concept Resourcing</td>\n",
       "      <td>\\n\\n£140 - £145 a day\\n</td>\n",
       "      <td>Are you a graduate in a numerical subject seek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Cubiq Recruitment</td>\n",
       "      <td>\\n\\n£30,000 - £75,000 a year\\n</td>\n",
       "      <td>Description\\nMachine Learning Engineer (Reinfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Newport</td>\n",
       "      <td>Concept Resourcing</td>\n",
       "      <td>\\n\\n£400 - £500 a day\\n</td>\n",
       "      <td>My client are a prestigious government organis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Location  \\\n",
       "0         Junior/Mid-Level Data Analyst or Scientist      Bristol   \n",
       "1                                     Data Scientist      Bristol   \n",
       "2   Senior Data Scientist - Electrical Power Systems      Bristol   \n",
       "3  Research Associate or Senior Research Associat...  Bristol BS8   \n",
       "4                          Machine Learning Engineer      Bristol   \n",
       "5    Senior Data Scientist - Bristol University Team      Bristol   \n",
       "6  Software Engineer (C++/Python), AI/Machine Lea...      Bristol   \n",
       "7                            Graduate Data Scientist      Newport   \n",
       "8                                   Machine Learning      Bristol   \n",
       "9                                     Data Scientist      Newport   \n",
       "\n",
       "                 Company                          Salary  \\\n",
       "0       Heat Recruitment  \\n\\n£25,000 - £40,000 a year\\n   \n",
       "1              Prolancer  \\n\\n£50,000 - £65,000 a year\\n   \n",
       "2               Toumetis                            None   \n",
       "3  University of Bristol  \\n\\n£33,797 - £38,017 a year\\n   \n",
       "4         Ultraleap Ltd.                            None   \n",
       "5             LV=Careers                            None   \n",
       "6          Linux Recruit  \\n\\n£45,000 - £70,000 a year\\n   \n",
       "7     Concept Resourcing         \\n\\n£140 - £145 a day\\n   \n",
       "8      Cubiq Recruitment  \\n\\n£30,000 - £75,000 a year\\n   \n",
       "9     Concept Resourcing         \\n\\n£400 - £500 a day\\n   \n",
       "\n",
       "                                         Description  \n",
       "0  I’m very pleased to be working with a superb B...  \n",
       "1  One of the world’s leading financial consultat...  \n",
       "2  TouMetis Job Description\\n\\nSenior Data Scient...  \n",
       "3  We have an exciting opportunity for a talented...  \n",
       "4  We are looking for an experienced and motivate...  \n",
       "5  Location\\nBristol\\nRef\\nGI007058\\nClosing date...  \n",
       "6  Artificial Intelligence, or simply 'AI', is on...  \n",
       "7  Are you a graduate in a numerical subject seek...  \n",
       "8  Description\\nMachine Learning Engineer (Reinfo...  \n",
       "9  My client are a prestigious government organis...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale up\n",
    "\n",
    "Now that we have our function to extract the raw data, we need to expand our search method. We can do so by including a range of cities and adding a limit to the number of results. The method is outlined in the notebook liked to the top of this page. Here I will simply copy and edit to my particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.indeed.co.uk', port=443): Max retries exceeded with url: /jobs?q=data%20scientist&l=Manchester&start=0 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f062fa499d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f062fa499d0>: Failed to establish a new connection: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    719\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.indeed.co.uk', port=443): Max retries exceeded with url: /jobs?q=data%20scientist&l=Manchester&start=0 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f062fa499d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a6d19879f69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_results_per_city\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# iterate in steps of 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8baa1fe01aa9>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Location\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Company\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Salary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"result\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.indeed.co.uk', port=443): Max retries exceeded with url: /jobs?q=data%20scientist&l=Manchester&start=0 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f062fa499d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))"
     ]
    }
   ],
   "source": [
    "url_template = \"https://www.indeed.co.uk/jobs?q=data%20scientist&l={}&start={}\"\n",
    "max_results_per_city = 2000 # set to a high value for more results\n",
    "\n",
    "cities = set([\"Bristol\",\"London\",\"Leeds\",\"Manchester\",\"Edinburgh\",\"Birmingham\",\"Liverpool\",\"Cardiff\"]) # will use a smaller sample for now\n",
    "#cities = set([\"Bristol\"])\n",
    "\n",
    "i = 0\n",
    "results=[]\n",
    "df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Description\"])\n",
    "for city in cities:\n",
    "    for start in range(0,max_results_per_city, 10): # iterate in steps of 10\n",
    "        url = url_template.format(city, start)\n",
    "        df_temp = parse(url)\n",
    "        df = df.append(df_temp, ignore_index=True)\n",
    "\n",
    "        # save the result as csv file\n",
    "df.to_csv('Indeed_project_uncleaned.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>QBE</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist\\nManchester/Leeds\\nWho we are\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>None</td>\n",
       "      <td>Job title: Senior Data Scientist\\n\\nLocation: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wilmslow</td>\n",
       "      <td>Warner Bros. Entertainment Group</td>\n",
       "      <td>None</td>\n",
       "      <td>Opportunity Overview\\nPlaydemic, a division of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Online Programming &amp; Data Science Private Tutor</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>ClassRx</td>\n",
       "      <td>\\n\\n£25 - £80 an hour\\n</td>\n",
       "      <td>ClassRx is a STEM focussed online tutoring com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Macclesfield</td>\n",
       "      <td>PHASTAR</td>\n",
       "      <td>None</td>\n",
       "      <td>THE COMPANYPHASTAR is a multiple award-winning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title      Location  \\\n",
       "0                                   Data Scientist    Manchester   \n",
       "1                            Senior Data Scientist    Manchester   \n",
       "2                                   Data Scientist      Wilmslow   \n",
       "3  Online Programming & Data Science Private Tutor    Manchester   \n",
       "4                            Senior Data Scientist  Macclesfield   \n",
       "\n",
       "                            Company                   Salary  \\\n",
       "0                               QBE                     None   \n",
       "1                       Booking.com                     None   \n",
       "2  Warner Bros. Entertainment Group                     None   \n",
       "3                           ClassRx  \\n\\n£25 - £80 an hour\\n   \n",
       "4                           PHASTAR                     None   \n",
       "\n",
       "                                         Description  \n",
       "0  Data Scientist\\nManchester/Leeds\\nWho we are\\n...  \n",
       "1  Job title: Senior Data Scientist\\n\\nLocation: ...  \n",
       "2  Opportunity Overview\\nPlaydemic, a division of...  \n",
       "3  ClassRx is a STEM focussed online tutoring com...  \n",
       "4  THE COMPANYPHASTAR is a multiple award-winning...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14757, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
